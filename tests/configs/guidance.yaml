model_engine_config:
  model: "bartowski/Llama-3.2-1B-Instruct-GGUF"
  filename: "*Q8_0.gguf"
  temperature: 0.0
max_tokens: 2048